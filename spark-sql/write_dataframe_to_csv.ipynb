{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad19b23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, LongType, IntegerType, ArrayType, Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41075a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/09 04:32:48 WARN Utils: Your hostname, Pavans-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.29.143 instead (on interface en0)\n",
      "23/02/09 04:32:48 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/09 04:32:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/02/09 04:32:50 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/02/09 04:32:50 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"sparksql-tutorial\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23b73d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the structure to the data frame\n",
    "schema = StructType([\n",
    "    StructField(name=\"FirstName\", dataType=StringType(), nullable=False),\n",
    "    StructField(name=\"LastName\", dataType=StringType(), nullable=False),\n",
    "    StructField(name=\"Age\", dataType=IntegerType(), nullable=False),\n",
    "    StructField(name=\"Place\", dataType=StringType(), nullable=False),\n",
    "    StructField(name=\"Salary\", dataType=LongType(), nullable=False),\n",
    "    StructField(name=\"Department\", dataType=StringType(), nullable=False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03512b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the data rows as per the schema defined\n",
    "rows = [\n",
    "    Row(\"Pavan\",\"Mantha\",36,\"Hyderabad\",273567,\"SPS\"),\n",
    "    Row(\"Arun\",\"Boppudi\",36,\"Guntur\",303567,\"Aero\"),\n",
    "    Row(\"Ravi\",\"Vadlamani\",26,\"Visakapatnam\",213567,\"Aero\"),\n",
    "    Row(\"Mahender\",\"M\",21,\"Hyderabad\",153567,\"Aero\"),\n",
    "    Row(\"Manoj\",\"Manoj\",21,\"Guntur\",183567,\"Aero\"),\n",
    "    Row(\"Manoj\",\"Velecheti\",21,\"Visakapatnam\",223567,\"Aero\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d8cb8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_rows = spark.sparkContext.parallelize(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e959f798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# createDataFrame is used to create dataframe manually\n",
    "df = spark.createDataFrame(parallel_rows, schema, verifySchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3831765a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---+------------+------+----------+\n",
      "|FirstName| LastName|Age|       Place|Salary|Department|\n",
      "+---------+---------+---+------------+------+----------+\n",
      "|    Pavan|   Mantha| 36|   Hyderabad|273567|       SPS|\n",
      "|     Arun|  Boppudi| 36|      Guntur|303567|      Aero|\n",
      "|     Ravi|Vadlamani| 26|Visakapatnam|213567|      Aero|\n",
      "| Mahender|        M| 21|   Hyderabad|153567|      Aero|\n",
      "|    Manoj|    Manoj| 21|      Guntur|183567|      Aero|\n",
      "|    Manoj|Velecheti| 21|Visakapatnam|223567|      Aero|\n",
      "+---------+---------+---+------------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "306733e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- FirstName: string (nullable = false)\n",
      " |-- LastName: string (nullable = false)\n",
      " |-- Age: integer (nullable = false)\n",
      " |-- Place: string (nullable = false)\n",
      " |-- Salary: long (nullable = false)\n",
      " |-- Department: string (nullable = false)\n",
      " |-- Technologies: array (nullable = false)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this will show the schema of the given dataframe\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52b47964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will create the folder named \"employee\" and create CSV files under it\n",
    "df.write.options(header=True, delimiter=\",\").csv(\"employee\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c38ba300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will create single CSV as partitionCount we made it as 1\n",
    "df.repartition(numPartitions=1).write.options(header=True, delimiter=\",\").csv(\"employee\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2ca479",
   "metadata": {},
   "source": [
    "## END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
