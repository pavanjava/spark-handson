{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c35ac040-ab92-4f22-b73f-31fd3d5c0143",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, LongType, IntegerType, ArrayType, Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/12 07:06:32 WARN Utils: Your hostname, Pavans-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.29.143 instead (on interface en0)\n",
      "23/02/12 07:06:32 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/12 07:06:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"sparksql-tutorial\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "af879ab2-be9f-4cfb-af23-bdc697d0748a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# define the structure to the data frame\n",
    "schema = StructType([\n",
    "    StructField(name=\"FirstName\", dataType=StringType(), nullable=False),\n",
    "    StructField(name=\"LastName\", dataType=StringType(), nullable=False),\n",
    "    StructField(name=\"Age\", dataType=IntegerType(), nullable=False),\n",
    "    StructField(name=\"Place\", dataType=StringType(), nullable=False),\n",
    "    StructField(name=\"Salary\", dataType=LongType(), nullable=False),\n",
    "    StructField(name=\"Department\", dataType=StringType(), nullable=False),\n",
    "    StructField(name=\"Technologies\", dataType=ArrayType(elementType=StringType()), nullable=False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de4fe831-210f-40c3-a8c3-a49ac8b1ebe0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create the data rows as per the schema defined\n",
    "rows = [\n",
    "    Row(\"Pavan\",\"Mantha\",36,\"Hyderabad\",273567,\"SPS\",[\"java\",\"spring boot\",\"data science\",\"react\",\"node\", \"Terraform\"]),\n",
    "    Row(\"Arun\",\"Boppudi\",36,\"Guntur\",303567,\"Aero\",[\"java\",\"spring boot\",\"cloud\",\"react\",\"node\", \"druid\", \"kafka\"]),\n",
    "    Row(\"Ravi\",\"Vadlamani\",26,\"Visakapatnam\",213567,\"Aero\",[\"express\",\"data structures\",\"react\"]),\n",
    "    Row(\"Mahender\",\"M\",21,\"Hyderabad\",153567,\"Aero\",[\"java\",\"spring boot\",\"express\",\"react\",\"node\"]),\n",
    "    Row(\"Manoj\",\"Manoj\",21,\"Guntur\",183567,\"Aero\",[\"express\",\"react\"]),\n",
    "    Row(\"Manoj\",\"Velecheti\",21,\"Visakapatnam\",223567,\"Aero\",[\"java\",\"spring boot\",\"express\",\"react\"]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12e62e7f-db0f-43e7-bb2e-4879cfb0b36e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "parallel_rows = spark.sparkContext.parallelize(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d3d0820f-844e-414a-8893-7434acac74e3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# createDataFrame is used to create dataframe manually\n",
    "df = spark.createDataFrame(parallel_rows, schema, verifySchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "10014d10-2e5f-4aa1-87e3-0dae17f29860",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---+------------+------+----------+--------------------+\n",
      "|FirstName| LastName|Age|       Place|Salary|Department|        Technologies|\n",
      "+---------+---------+---+------------+------+----------+--------------------+\n",
      "|    Pavan|   Mantha| 36|   Hyderabad|273567|       SPS|[java, spring boo...|\n",
      "|     Arun|  Boppudi| 36|      Guntur|303567|      Aero|[java, spring boo...|\n",
      "|     Ravi|Vadlamani| 26|Visakapatnam|213567|      Aero|[express, data st...|\n",
      "| Mahender|        M| 21|   Hyderabad|153567|      Aero|[java, spring boo...|\n",
      "|    Manoj|    Manoj| 21|      Guntur|183567|      Aero|    [express, react]|\n",
      "|    Manoj|Velecheti| 21|Visakapatnam|223567|      Aero|[java, spring boo...|\n",
      "+---------+---------+---+------------+------+----------+--------------------+\n",
      "\n",
      "root\n",
      " |-- FirstName: string (nullable = false)\n",
      " |-- LastName: string (nullable = false)\n",
      " |-- Age: integer (nullable = false)\n",
      " |-- Place: string (nullable = false)\n",
      " |-- Salary: long (nullable = false)\n",
      " |-- Department: string (nullable = false)\n",
      " |-- Technologies: array (nullable = false)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "825d2e29-6cb5-49d6-818c-7f77d64390a7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Help on method withColumn in module pyspark.sql.dataframe:\n",
       "\n",
       "withColumn(colName: str, col: pyspark.sql.column.Column) -> 'DataFrame' method of pyspark.sql.dataframe.DataFrame instance\n",
       "    Returns a new :class:`DataFrame` by adding a column or replacing the\n",
       "    existing column that has the same name.\n",
       "    \n",
       "    The column expression must be an expression over this :class:`DataFrame`; attempting to add\n",
       "    a column from some other :class:`DataFrame` will raise an error.\n",
       "    \n",
       "    .. versionadded:: 1.3.0\n",
       "    \n",
       "    .. versionchanged:: 3.4.0\n",
       "        Support Spark Connect.\n",
       "    \n",
       "    Parameters\n",
       "    ----------\n",
       "    colName : str\n",
       "        string, name of the new column.\n",
       "    col : :class:`Column`\n",
       "        a :class:`Column` expression for the new column.\n",
       "    \n",
       "    Notes\n",
       "    -----\n",
       "    This method introduces a projection internally. Therefore, calling it multiple\n",
       "    times, for instance, via loops in order to add multiple columns can generate big\n",
       "    plans which can cause performance issues and even `StackOverflowException`.\n",
       "    To avoid this, use :func:`select` with the multiple columns at once.\n",
       "    \n",
       "    Examples\n",
       "    --------\n",
       "    >>> df.withColumn('age2', df.age + 2).collect()\n",
       "    [Row(age=2, name='Alice', age2=4), Row(age=5, name='Bob', age2=7)]\n",
       "\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "Help on method withColumn in module pyspark.sql.dataframe:\n\nwithColumn(colName: str, col: pyspark.sql.column.Column) -> 'DataFrame' method of pyspark.sql.dataframe.DataFrame instance\n    Returns a new :class:`DataFrame` by adding a column or replacing the\n    existing column that has the same name.\n    \n    The column expression must be an expression over this :class:`DataFrame`; attempting to add\n    a column from some other :class:`DataFrame` will raise an error.\n    \n    .. versionadded:: 1.3.0\n    \n    .. versionchanged:: 3.4.0\n        Support Spark Connect.\n    \n    Parameters\n    ----------\n    colName : str\n        string, name of the new column.\n    col : :class:`Column`\n        a :class:`Column` expression for the new column.\n    \n    Notes\n    -----\n    This method introduces a projection internally. Therefore, calling it multiple\n    times, for instance, via loops in order to add multiple columns can generate big\n    plans which can cause performance issues and even `StackOverflowException`.\n    To avoid this, use :func:`select` with the multiple columns at once.\n    \n    Examples\n    --------\n    >>> df.withColumn('age2', df.age + 2).collect()\n    [Row(age=2, name='Alice', age2=4), Row(age=5, name='Bob', age2=7)]\n\n",
       "datasetInfos": [],
       "metadata": {},
       "name": null,
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "help(df.withColumn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "43b3a7ce-113c-4402-a360-f75215e2da31",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3c1f27b5-63b6-41ac-8653-bc7504afcda1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.withColumn(colName='Salary', col=F.col('Salary').cast('Double'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0cb8cb6-c5f8-4a1c-89cc-bb2215dda445",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- FirstName: string (nullable = false)\n",
      " |-- LastName: string (nullable = false)\n",
      " |-- Age: integer (nullable = false)\n",
      " |-- Place: string (nullable = false)\n",
      " |-- Salary: double (nullable = false)\n",
      " |-- Department: string (nullable = false)\n",
      " |-- Technologies: array (nullable = false)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2ffe6949-f5d3-4079-9b79-4bebc1a0613a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---+------------+--------+----------+--------------------+\n",
      "|FirstName| LastName|Age|       Place|  Salary|Department|        Technologies|\n",
      "+---------+---------+---+------------+--------+----------+--------------------+\n",
      "|    Pavan|   Mantha| 36|   Hyderabad|273567.0|       SPS|[java, spring boo...|\n",
      "|     Arun|  Boppudi| 36|      Guntur|303567.0|      Aero|[java, spring boo...|\n",
      "|     Ravi|Vadlamani| 26|Visakapatnam|213567.0|      Aero|[express, data st...|\n",
      "| Mahender|        M| 21|   Hyderabad|153567.0|      Aero|[java, spring boo...|\n",
      "|    Manoj|    Manoj| 21|      Guntur|183567.0|      Aero|    [express, react]|\n",
      "|    Manoj|Velecheti| 21|Visakapatnam|223567.0|      Aero|[java, spring boo...|\n",
      "+---------+---------+---+------------+--------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "927fe067-5576-4f27-b95d-c8569cb5e6bc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#double the salary of every employee\n",
    "df = df.withColumn(colName='Salary', col=F.col('Salary')*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef29bb09-87f2-47be-8783-f0ae665d81bb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---+------------+--------+----------+---------------------------------------------------------+\n",
      "|FirstName|LastName |Age|Place       |Salary  |Department|Technologies                                             |\n",
      "+---------+---------+---+------------+--------+----------+---------------------------------------------------------+\n",
      "|Pavan    |Mantha   |36 |Hyderabad   |547134.0|SPS       |[java, spring boot, data science, react, node, Terraform]|\n",
      "|Arun     |Boppudi  |36 |Guntur      |607134.0|Aero      |[java, spring boot, cloud, react, node, druid, kafka]    |\n",
      "|Ravi     |Vadlamani|26 |Visakapatnam|427134.0|Aero      |[express, data structures, react]                        |\n",
      "|Mahender |M        |21 |Hyderabad   |307134.0|Aero      |[java, spring boot, express, react, node]                |\n",
      "|Manoj    |Manoj    |21 |Guntur      |367134.0|Aero      |[express, react]                                         |\n",
      "|Manoj    |Velecheti|21 |Visakapatnam|447134.0|Aero      |[java, spring boot, express, react]                      |\n",
      "+---------+---------+---+------------+--------+----------+---------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3cbf529d-e44b-4d9c-a4df-f56b98b34ca3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.withColumn('Experience', F.lit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef83b23a-de91-4dd2-96f3-823b2188bff8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---+------------+--------+----------+--------------------+----------+\n",
      "|FirstName| LastName|Age|       Place|  Salary|Department|        Technologies|Experience|\n",
      "+---------+---------+---+------------+--------+----------+--------------------+----------+\n",
      "|    Pavan|   Mantha| 36|   Hyderabad|547134.0|       SPS|[java, spring boo...|        10|\n",
      "|     Arun|  Boppudi| 36|      Guntur|607134.0|      Aero|[java, spring boo...|        10|\n",
      "|     Ravi|Vadlamani| 26|Visakapatnam|427134.0|      Aero|[express, data st...|        10|\n",
      "| Mahender|        M| 21|   Hyderabad|307134.0|      Aero|[java, spring boo...|        10|\n",
      "|    Manoj|    Manoj| 21|      Guntur|367134.0|      Aero|    [express, react]|        10|\n",
      "|    Manoj|Velecheti| 21|Visakapatnam|447134.0|      Aero|[java, spring boo...|        10|\n",
      "+---------+---------+---+------------+--------+----------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9105d60c-1c12-4ac4-9b6c-6e1456bb09de",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.withColumn('Experience', F.when(F.col('Age') < 26, F.col('Experience')/2).otherwise(F.col('Experience')*1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9f287d7a-315c-449d-922f-c38017eebb44",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---+------------+--------+----------+--------------------+----------+\n",
      "|FirstName| LastName|Age|       Place|  Salary|Department|        Technologies|Experience|\n",
      "+---------+---------+---+------------+--------+----------+--------------------+----------+\n",
      "|    Pavan|   Mantha| 36|   Hyderabad|547134.0|       SPS|[java, spring boo...|      10.0|\n",
      "|     Arun|  Boppudi| 36|      Guntur|607134.0|      Aero|[java, spring boo...|      10.0|\n",
      "|     Ravi|Vadlamani| 26|Visakapatnam|427134.0|      Aero|[express, data st...|      10.0|\n",
      "| Mahender|        M| 21|   Hyderabad|307134.0|      Aero|[java, spring boo...|       5.0|\n",
      "|    Manoj|    Manoj| 21|      Guntur|367134.0|      Aero|    [express, react]|       5.0|\n",
      "|    Manoj|Velecheti| 21|Visakapatnam|447134.0|      Aero|[java, spring boo...|       5.0|\n",
      "+---------+---------+---+------------+--------+----------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f7f8b103-91f3-4892-921a-16a93a99745c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "use_withColumn",
   "notebookOrigID": 375693927970997,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
