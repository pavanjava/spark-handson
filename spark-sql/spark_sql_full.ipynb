{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/19 15:31:31 WARN Utils: Your hostname, Pavans-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.29.143 instead (on interface en0)\n",
      "23/03/19 15:31:31 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/19 15:31:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"sparkdev-tutorial\").getOrCreate()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "# define the structure to the data frame\n",
    "schema = StructType([\n",
    "    StructField(name=\"FirstName\", dataType=StringType(), nullable=False),\n",
    "    StructField(name=\"LastName\", dataType=StringType(), nullable=False),\n",
    "    StructField(name=\"Age\", dataType=IntegerType(), nullable=False),\n",
    "    StructField(name=\"Place\", dataType=StringType(), nullable=False),\n",
    "    StructField(name=\"Salary\", dataType=LongType(), nullable=False),\n",
    "    StructField(name=\"Department\", dataType=StringType(), nullable=False),\n",
    "    StructField(name=\"Technologies\", dataType=ArrayType(elementType=StringType()), nullable=False),\n",
    "])\n",
    "\n",
    "# create the data rows as per the schema defined\n",
    "rows = [\n",
    "    Row(\"Pavan\",\"Mantha\",36,\"Hyderabad\",273567,\"SPS\",[\"java\",\"spring boot\",\"data science\",\"react\",\"node\", \"Terraform\"]),\n",
    "    Row(\"Arun\",\"Boppudi\",36,\"Guntur\",303567,\"Aero\",[\"java\",\"spring boot\",\"cloud\",\"react\",\"node\", \"druid\", \"kafka\"]),\n",
    "    Row(\"Ravi\",\"Vadlamani\",26,\"Visakapatnam\",213567,\"Aero\",[\"express\",\"data structures\",\"react\"]),\n",
    "    Row(\"Mahender\",\"M\",21,\"Hyderabad\",153567,\"Aero\",[\"java\",\"spring boot\",\"express\",\"react\",\"node\"]),\n",
    "    Row(\"Manoj\",\"Manoj\",21,\"Guntur\",183567,\"Aero\",[\"express\",\"react\"]),\n",
    "    Row(\"Manoj\",\"Velecheti\",21,\"Visakapatnam\",223567,\"Aero\",[\"java\",\"spring boot\",\"express\",\"react\"]),\n",
    "    Row(\"Phani\",\"Vadlmani\",21,\"Anakapalli\",283467,\"AppDev\",[\"express\",\"react\", \"Docker\", \"AWS\"]),\n",
    "    Row(\"Deepak\",\"Mantha\",33,\"Chennai\",303467,\"DAE\",[\"C\",\"C++\", \"Python\", \"Physics\", \"Mathematics\"]),\n",
    "]\n",
    "\n",
    "parallel_rows = spark.sparkContext.parallelize(rows)\n",
    "\n",
    "# createDataFrame is used to create dataframe manually\n",
    "df = spark.createDataFrame(parallel_rows, schema, verifySchema=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Use of PySpark Select() function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---+------------+------+----------+---------------------------------------------------------+\n",
      "|FirstName|LastName |Age|Place       |Salary|Department|Technologies                                             |\n",
      "+---------+---------+---+------------+------+----------+---------------------------------------------------------+\n",
      "|Pavan    |Mantha   |36 |Hyderabad   |273567|SPS       |[java, spring boot, data science, react, node, Terraform]|\n",
      "|Arun     |Boppudi  |36 |Guntur      |303567|Aero      |[java, spring boot, cloud, react, node, druid, kafka]    |\n",
      "|Ravi     |Vadlamani|26 |Visakapatnam|213567|Aero      |[express, data structures, react]                        |\n",
      "|Mahender |M        |21 |Hyderabad   |153567|Aero      |[java, spring boot, express, react, node]                |\n",
      "|Manoj    |Manoj    |21 |Guntur      |183567|Aero      |[express, react]                                         |\n",
      "|Manoj    |Velecheti|21 |Visakapatnam|223567|Aero      |[java, spring boot, express, react]                      |\n",
      "|Phani    |Vadlmani |21 |Anakapalli  |283467|AppDev    |[express, react, Docker, AWS]                            |\n",
      "|Deepak   |Mantha   |33 |Chennai     |303467|DAE       |[C, C++, Python, Physics, Mathematics]                   |\n",
      "+---------+---------+---+------------+------+----------+---------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"*\").show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+---------------------------------------------------------+\n",
      "|FirstName|Salary|Technologies                                             |\n",
      "+---------+------+---------------------------------------------------------+\n",
      "|Pavan    |273567|[java, spring boot, data science, react, node, Terraform]|\n",
      "|Arun     |303567|[java, spring boot, cloud, react, node, druid, kafka]    |\n",
      "|Ravi     |213567|[express, data structures, react]                        |\n",
      "|Mahender |153567|[java, spring boot, express, react, node]                |\n",
      "|Manoj    |183567|[express, react]                                         |\n",
      "|Manoj    |223567|[java, spring boot, express, react]                      |\n",
      "|Phani    |283467|[express, react, Docker, AWS]                            |\n",
      "|Deepak   |303467|[C, C++, Python, Physics, Mathematics]                   |\n",
      "+---------+------+---------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col(\"FirstName\"), col(\"Salary\"), col(\"Technologies\")).show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "data = [\n",
    "    ((\"Pavan\",\"Kumar\",\"Mantha\"),\"TS\",\"M\"),\n",
    "    ((\"Divyasree\",None,\"Gottipati\"),\"TS\",\"F\"),\n",
    "    ((\"Ramarao\",None,\"Dandamudi\"),\"AP\",\"M\"),\n",
    "    ((\"Snigdha\",\"\",\"Kantamaneni\"),\"TS\",\"F\"),\n",
    "    ((\"Mahender\",None,None),\"TS\",\"M\"),\n",
    "    ((\"Ramu\",None,\"Nagisetty\"),\"AP\",\"M\"),\n",
    "    ((\"Dhawan\",None,\"Rachakonda\"),\"TS\",\"M\")\n",
    "]\n",
    "\n",
    "schema = StructType([\n",
    "    StructField('name', StructType([\n",
    "        StructField('firstname', StringType(), True),\n",
    "        StructField('middlename', StringType(), True),\n",
    "        StructField('lastname', StringType(), True)\n",
    "    ])),\n",
    "    StructField('state', StringType(), True),\n",
    "    StructField('gender', StringType(), True)\n",
    "])\n",
    "\n",
    "df2 = spark.createDataFrame(data=data, schema=schema)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      "\n",
      "+----------------------------+-----+------+\n",
      "|name                        |state|gender|\n",
      "+----------------------------+-----+------+\n",
      "|{Pavan, Kumar, Mantha}      |TS   |M     |\n",
      "|{Divyasree, null, Gottipati}|TS   |F     |\n",
      "|{Ramarao, null, Dandamudi}  |AP   |M     |\n",
      "|{Snigdha, , Kantamaneni}    |TS   |F     |\n",
      "|{Mahender, null, null}      |TS   |M     |\n",
      "|{Ramu, null, Nagisetty}     |AP   |M     |\n",
      "|{Dhawan, null, Rachakonda}  |TS   |M     |\n",
      "+----------------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()\n",
    "df2.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+\n",
      "|name                        |\n",
      "+----------------------------+\n",
      "|{Pavan, Kumar, Mantha}      |\n",
      "|{Divyasree, null, Gottipati}|\n",
      "|{Ramarao, null, Dandamudi}  |\n",
      "|{Snigdha, , Kantamaneni}    |\n",
      "|{Mahender, null, null}      |\n",
      "|{Ramu, null, Nagisetty}     |\n",
      "|{Dhawan, null, Rachakonda}  |\n",
      "+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.select(col(\"name\")).show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|lastname   |\n",
      "+-----------+\n",
      "|Mantha     |\n",
      "|Gottipati  |\n",
      "|Dandamudi  |\n",
      "|Kantamaneni|\n",
      "|null       |\n",
      "|Nagisetty  |\n",
      "|Rachakonda |\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.select(\"name.lastname\").show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Use of PySpark Collect() function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(FirstName='Pavan', LastName='Mantha', Age=36, Place='Hyderabad', Salary=273567, Department='SPS', Technologies=['java', 'spring boot', 'data science', 'react', 'node', 'Terraform']), Row(FirstName='Arun', LastName='Boppudi', Age=36, Place='Guntur', Salary=303567, Department='Aero', Technologies=['java', 'spring boot', 'cloud', 'react', 'node', 'druid', 'kafka']), Row(FirstName='Ravi', LastName='Vadlamani', Age=26, Place='Visakapatnam', Salary=213567, Department='Aero', Technologies=['express', 'data structures', 'react']), Row(FirstName='Mahender', LastName='M', Age=21, Place='Hyderabad', Salary=153567, Department='Aero', Technologies=['java', 'spring boot', 'express', 'react', 'node']), Row(FirstName='Manoj', LastName='Manoj', Age=21, Place='Guntur', Salary=183567, Department='Aero', Technologies=['express', 'react']), Row(FirstName='Manoj', LastName='Velecheti', Age=21, Place='Visakapatnam', Salary=223567, Department='Aero', Technologies=['java', 'spring boot', 'express', 'react']), Row(FirstName='Phani', LastName='Vadlmani', Age=21, Place='Anakapalli', Salary=283467, Department='AppDev', Technologies=['express', 'react', 'Docker', 'AWS']), Row(FirstName='Deepak', LastName='Mantha', Age=33, Place='Chennai', Salary=303467, Department='DAE', Technologies=['C', 'C++', 'Python', 'Physics', 'Mathematics'])]\n"
     ]
    }
   ],
   "source": [
    "dfCollected = df.collect()\n",
    "print(dfCollected)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pavan => Hyderabad\n",
      "Arun => Guntur\n",
      "Ravi => Visakapatnam\n",
      "Mahender => Hyderabad\n",
      "Manoj => Guntur\n",
      "Manoj => Visakapatnam\n",
      "Phani => Anakapalli\n",
      "Deepak => Chennai\n"
     ]
    }
   ],
   "source": [
    "for row in dfCollected:\n",
    "    print(row[\"FirstName\"] +\" => \"+ row[\"Place\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Note: Select() is a transformation function while Collect() is a action function. Select() gives a new DF with seleceted columns while Collect() gives the entire DF. most of the time we should avoid using Collect()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## use of PySpark withColumn() function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---+------------+------+----------+--------------------+--------------+\n",
      "|FirstName| LastName|Age|       Place|Salary|Department|        Technologies|modifiedSalary|\n",
      "+---------+---------+---+------------+------+----------+--------------------+--------------+\n",
      "|    Pavan|   Mantha| 36|   Hyderabad|273567|       SPS|[java, spring boo...|        547134|\n",
      "|     Arun|  Boppudi| 36|      Guntur|303567|      Aero|[java, spring boo...|        607134|\n",
      "|     Ravi|Vadlamani| 26|Visakapatnam|213567|      Aero|[express, data st...|        427134|\n",
      "| Mahender|        M| 21|   Hyderabad|153567|      Aero|[java, spring boo...|        307134|\n",
      "|    Manoj|    Manoj| 21|      Guntur|183567|      Aero|    [express, react]|        367134|\n",
      "|    Manoj|Velecheti| 21|Visakapatnam|223567|      Aero|[java, spring boo...|        447134|\n",
      "|    Phani| Vadlmani| 21|  Anakapalli|283467|    AppDev|[express, react, ...|        566934|\n",
      "|   Deepak|   Mantha| 33|     Chennai|303467|       DAE|[C, C++, Python, ...|        606934|\n",
      "+---------+---------+---+------------+------+----------+--------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"modifiedSalary\", col(\"salary\")*2)\n",
    "df.show(truncate=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---+------------+------+----------+--------------------+--------------+-----+\n",
      "|FirstName| LastName|Age|       Place|Salary|Department|        Technologies|modifiedSalary|State|\n",
      "+---------+---------+---+------------+------+----------+--------------------+--------------+-----+\n",
      "|    Pavan|   Mantha| 36|   Hyderabad|273567|       SPS|[java, spring boo...|        547134|   AP|\n",
      "|     Arun|  Boppudi| 36|      Guntur|303567|      Aero|[java, spring boo...|        607134|   AP|\n",
      "|     Ravi|Vadlamani| 26|Visakapatnam|213567|      Aero|[express, data st...|        427134|   AP|\n",
      "| Mahender|        M| 21|   Hyderabad|153567|      Aero|[java, spring boo...|        307134|   AP|\n",
      "|    Manoj|    Manoj| 21|      Guntur|183567|      Aero|    [express, react]|        367134|   AP|\n",
      "|    Manoj|Velecheti| 21|Visakapatnam|223567|      Aero|[java, spring boo...|        447134|   AP|\n",
      "|    Phani| Vadlmani| 21|  Anakapalli|283467|    AppDev|[express, react, ...|        566934|   AP|\n",
      "|   Deepak|   Mantha| 33|     Chennai|303467|       DAE|[C, C++, Python, ...|        606934|   AP|\n",
      "+---------+---------+---+------------+------+----------+--------------------+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"State\", lit(\"AP\"))\n",
    "df.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## use of when() function in pyspark"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---+------------+------+----------+--------------------+--------------+-----+\n",
      "|FirstName| LastName|Age|       Place|Salary|Department|        Technologies|modifiedSalary|State|\n",
      "+---------+---------+---+------------+------+----------+--------------------+--------------+-----+\n",
      "|    Pavan|   Mantha| 36|   Hyderabad|273567|       SPS|[java, spring boo...|        547134|   TS|\n",
      "|     Arun|  Boppudi| 36|      Guntur|303567|      Aero|[java, spring boo...|        607134|   AP|\n",
      "|     Ravi|Vadlamani| 26|Visakapatnam|213567|      Aero|[express, data st...|        427134|   AP|\n",
      "| Mahender|        M| 21|   Hyderabad|153567|      Aero|[java, spring boo...|        307134|   TS|\n",
      "|    Manoj|    Manoj| 21|      Guntur|183567|      Aero|    [express, react]|        367134|   AP|\n",
      "|    Manoj|Velecheti| 21|Visakapatnam|223567|      Aero|[java, spring boo...|        447134|   AP|\n",
      "|    Phani| Vadlmani| 21|  Anakapalli|283467|    AppDev|[express, react, ...|        566934|   AP|\n",
      "|   Deepak|   Mantha| 33|     Chennai|303467|       DAE|[C, C++, Python, ...|        606934|   TN|\n",
      "+---------+---------+---+------------+------+----------+--------------------+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"State\", when(df.Place == \"Chennai\", \"TN\").otherwise(when(df.Place == \"Hyderabad\", \"TS\").otherwise(\"AP\")))\n",
    "df.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## use of where() & filter() function in pyspark"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---+------------+------+----------+--------------------+--------------+-----+\n",
      "|FirstName| LastName|Age|       Place|Salary|Department|        Technologies|modifiedSalary|State|\n",
      "+---------+---------+---+------------+------+----------+--------------------+--------------+-----+\n",
      "|     Arun|  Boppudi| 36|      Guntur|303567|      Aero|[java, spring boo...|        607134|   AP|\n",
      "|     Ravi|Vadlamani| 26|Visakapatnam|213567|      Aero|[express, data st...|        427134|   AP|\n",
      "|    Manoj|    Manoj| 21|      Guntur|183567|      Aero|    [express, react]|        367134|   AP|\n",
      "|    Manoj|Velecheti| 21|Visakapatnam|223567|      Aero|[java, spring boo...|        447134|   AP|\n",
      "|    Phani| Vadlmani| 21|  Anakapalli|283467|    AppDev|[express, react, ...|        566934|   AP|\n",
      "+---------+---------+---+------------+------+----------+--------------------+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df[\"State\"] == \"AP\").show(truncate=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+-----+------+\n",
      "|name                        |state|gender|\n",
      "+----------------------------+-----+------+\n",
      "|{Divyasree, null, Gottipati}|TS   |F     |\n",
      "|{Snigdha, , Kantamaneni}    |TS   |F     |\n",
      "+----------------------------+-----+------+\n",
      "\n",
      "+--------------------------+-----+------+\n",
      "|name                      |state|gender|\n",
      "+--------------------------+-----+------+\n",
      "|{Pavan, Kumar, Mantha}    |TS   |M     |\n",
      "|{Ramarao, null, Dandamudi}|AP   |M     |\n",
      "|{Mahender, null, null}    |TS   |M     |\n",
      "|{Ramu, null, Nagisetty}   |AP   |M     |\n",
      "|{Dhawan, null, Rachakonda}|TS   |M     |\n",
      "+--------------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using equals condition\n",
    "df2.filter(df2.gender == \"F\").show(truncate=False)\n",
    "\n",
    "# Using equals condition\n",
    "df2.filter(df2.gender != \"F\").show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+---+------+------+----------+-----------------------------------------------------+--------------+-----+\n",
      "|FirstName|LastName|Age|Place |Salary|Department|Technologies                                         |modifiedSalary|State|\n",
      "+---------+--------+---+------+------+----------+-----------------------------------------------------+--------------+-----+\n",
      "|Arun     |Boppudi |36 |Guntur|303567|Aero      |[java, spring boot, cloud, react, node, druid, kafka]|607134        |AP   |\n",
      "+---------+--------+---+------+------+----------+-----------------------------------------------------+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(array_contains(df.Technologies, \"druid\")).show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+---+---------+------+----------+--------------------+--------------+-----+\n",
      "|FirstName|LastName|Age|    Place|Salary|Department|        Technologies|modifiedSalary|State|\n",
      "+---------+--------+---+---------+------+----------+--------------------+--------------+-----+\n",
      "|    Pavan|  Mantha| 36|Hyderabad|273567|       SPS|[java, spring boo...|        547134|   TS|\n",
      "|     Arun| Boppudi| 36|   Guntur|303567|      Aero|[java, spring boo...|        607134|   AP|\n",
      "|   Deepak|  Mantha| 33|  Chennai|303467|       DAE|[C, C++, Python, ...|        606934|   TN|\n",
      "+---------+--------+---+---------+------+----------+--------------------+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(col(\"Age\") > 30).show(truncate=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Note: where() and filter() function both are used to filter the results from the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## use of orderBy() and sort() in pyspark"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---+------------+------+----------+--------------------+--------------+-----+\n",
      "|FirstName| LastName|Age|       Place|Salary|Department|        Technologies|modifiedSalary|State|\n",
      "+---------+---------+---+------------+------+----------+--------------------+--------------+-----+\n",
      "|    Manoj|Velecheti| 21|Visakapatnam|223567|      Aero|[java, spring boo...|        447134|   AP|\n",
      "| Mahender|        M| 21|   Hyderabad|153567|      Aero|[java, spring boo...|        307134|   TS|\n",
      "|    Manoj|    Manoj| 21|      Guntur|183567|      Aero|    [express, react]|        367134|   AP|\n",
      "|    Phani| Vadlmani| 21|  Anakapalli|283467|    AppDev|[express, react, ...|        566934|   AP|\n",
      "|     Ravi|Vadlamani| 26|Visakapatnam|213567|      Aero|[express, data st...|        427134|   AP|\n",
      "|   Deepak|   Mantha| 33|     Chennai|303467|       DAE|[C, C++, Python, ...|        606934|   TN|\n",
      "|     Arun|  Boppudi| 36|      Guntur|303567|      Aero|[java, spring boo...|        607134|   AP|\n",
      "|    Pavan|   Mantha| 36|   Hyderabad|273567|       SPS|[java, spring boo...|        547134|   TS|\n",
      "+---------+---------+---+------------+------+----------+--------------------+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort(\"Age\", \"Department\").show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---+------------+------+----------+---------------------------------------------------------+\n",
      "|FirstName|LastName |Age|Place       |Salary|Department|Technologies                                             |\n",
      "+---------+---------+---+------------+------+----------+---------------------------------------------------------+\n",
      "|Mahender |M        |21 |Hyderabad   |153567|Aero      |[java, spring boot, express, react, node]                |\n",
      "|Manoj    |Manoj    |21 |Guntur      |183567|Aero      |[express, react]                                         |\n",
      "|Ravi     |Vadlamani|26 |Visakapatnam|213567|Aero      |[express, data structures, react]                        |\n",
      "|Manoj    |Velecheti|21 |Visakapatnam|223567|Aero      |[java, spring boot, express, react]                      |\n",
      "|Pavan    |Mantha   |36 |Hyderabad   |273567|SPS       |[java, spring boot, data science, react, node, Terraform]|\n",
      "|Phani    |Vadlmani |21 |Anakapalli  |283467|AppDev    |[express, react, Docker, AWS]                            |\n",
      "|Deepak   |Mantha   |33 |Chennai     |303467|DAE       |[C, C++, Python, Physics, Mathematics]                   |\n",
      "|Arun     |Boppudi  |36 |Guntur      |303567|Aero      |[java, spring boot, cloud, react, node, druid, kafka]    |\n",
      "+---------+---------+---+------------+------+----------+---------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort(col(\"Salary\").asc()).show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+-----+------+\n",
      "|name                        |state|gender|\n",
      "+----------------------------+-----+------+\n",
      "|{Ramarao, null, Dandamudi}  |AP   |M     |\n",
      "|{Ramu, null, Nagisetty}     |AP   |M     |\n",
      "|{Mahender, null, null}      |TS   |M     |\n",
      "|{Divyasree, null, Gottipati}|TS   |F     |\n",
      "|{Snigdha, , Kantamaneni}    |TS   |F     |\n",
      "|{Dhawan, null, Rachakonda}  |TS   |M     |\n",
      "|{Pavan, Kumar, Mantha}      |TS   |M     |\n",
      "+----------------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.orderBy(col(\"state\")).show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+-----+------+\n",
      "|name                        |state|gender|\n",
      "+----------------------------+-----+------+\n",
      "|{Ramarao, null, Dandamudi}  |AP   |M     |\n",
      "|{Ramu, null, Nagisetty}     |AP   |M     |\n",
      "|{Dhawan, null, Rachakonda}  |TS   |M     |\n",
      "|{Divyasree, null, Gottipati}|TS   |F     |\n",
      "|{Mahender, null, null}      |TS   |M     |\n",
      "|{Pavan, Kumar, Mantha}      |TS   |M     |\n",
      "|{Snigdha, , Kantamaneni}    |TS   |F     |\n",
      "+----------------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.orderBy(col(\"state\"), col(\"name.firstname\")).show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## use of groupBy() function in pyspark"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 44:===========>                                             (2 + 8) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|Department|sum(Salary)|\n",
      "+----------+-----------+\n",
      "|       SPS|     273567|\n",
      "|      Aero|    1077835|\n",
      "|    AppDev|     283467|\n",
      "|       DAE|     303467|\n",
      "+----------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.groupBy(col(\"Department\")).sum(\"Salary\").show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|Department|max(Salary)|\n",
      "+----------+-----------+\n",
      "|       SPS|     273567|\n",
      "|      Aero|     303567|\n",
      "|    AppDev|     283467|\n",
      "|       DAE|     303467|\n",
      "+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(col(\"Department\")).max(\"Salary\").show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---+------------+------+----------+--------------------+--------------+-----+-----+\n",
      "|FirstName| LastName|Age|       Place|Salary|Department|        Technologies|modifiedSalary|State|Bonus|\n",
      "+---------+---------+---+------------+------+----------+--------------------+--------------+-----+-----+\n",
      "|    Pavan|   Mantha| 36|   Hyderabad|273567|       SPS|[java, spring boo...|        547134|   TS| 2000|\n",
      "|     Arun|  Boppudi| 36|      Guntur|303567|      Aero|[java, spring boo...|        607134|   AP| 2000|\n",
      "|     Ravi|Vadlamani| 26|Visakapatnam|213567|      Aero|[express, data st...|        427134|   AP| 2000|\n",
      "| Mahender|        M| 21|   Hyderabad|153567|      Aero|[java, spring boo...|        307134|   TS| 2000|\n",
      "|    Manoj|    Manoj| 21|      Guntur|183567|      Aero|    [express, react]|        367134|   AP| 2000|\n",
      "|    Manoj|Velecheti| 21|Visakapatnam|223567|      Aero|[java, spring boo...|        447134|   AP| 2000|\n",
      "|    Phani| Vadlmani| 21|  Anakapalli|283467|    AppDev|[express, react, ...|        566934|   AP| 2000|\n",
      "|   Deepak|   Mantha| 33|     Chennai|303467|       DAE|[C, C++, Python, ...|        606934|   TN| 2000|\n",
      "+---------+---------+---+------------+------+----------+--------------------+--------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"Bonus\", lit(2000))\n",
    "df.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+-----------+----------+\n",
      "|Department|       Place|sum(Salary)|sum(Bonus)|\n",
      "+----------+------------+-----------+----------+\n",
      "|       SPS|   Hyderabad|     273567|      2000|\n",
      "|      Aero|      Guntur|     487134|      4000|\n",
      "|      Aero|Visakapatnam|     437134|      4000|\n",
      "|      Aero|   Hyderabad|     153567|      2000|\n",
      "|    AppDev|  Anakapalli|     283467|      2000|\n",
      "|       DAE|     Chennai|     303467|      2000|\n",
      "+----------+------------+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#GroupBy on multiple columns\n",
    "df.groupBy(\"Department\",\"Place\").sum(\"Salary\",\"Bonus\").show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## use of join() function in pyspark"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### will demonstrate with a classic example of employee and department dataframe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- emp_id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- manager_id: long (nullable = true)\n",
      " |-- year_joined: string (nullable = true)\n",
      " |-- dept_id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n",
      "+------+-------------------+----------+-----------+-------+------+------+\n",
      "|emp_id|name               |manager_id|year_joined|dept_id|gender|salary|\n",
      "+------+-------------------+----------+-----------+-------+------+------+\n",
      "|1     |Pavan Mantha       |-1        |2018       |10     |M     |3000  |\n",
      "|2     |Ramarao Dandamudi  |1         |2010       |20     |M     |4000  |\n",
      "|3     |Mahender           |1         |2010       |10     |M     |1000  |\n",
      "|4     |Snigdha Kantamaneni|3         |2005       |10     |F     |2000  |\n",
      "|5     |Divyasree Gothipati|3         |2010       |40     |F     |1500  |\n",
      "|6     |Ramu Nagisetty     |1         |2010       |50     |M     |2800  |\n",
      "|7     |Dhawan Rachakonda  |2         |2010       |50     |M     |3600  |\n",
      "+------+-------------------+----------+-----------+-------+------+------+\n",
      "\n",
      "root\n",
      " |-- dept_name: string (nullable = true)\n",
      " |-- dept_id: long (nullable = true)\n",
      "\n",
      "+---------+-------+\n",
      "|dept_name|dept_id|\n",
      "+---------+-------+\n",
      "|Finance  |10     |\n",
      "|Marketing|20     |\n",
      "|Sales    |30     |\n",
      "|IT       |40     |\n",
      "+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp = [(1,\"Pavan Mantha\",-1,\"2018\",\"10\",\"M\",3000),\n",
    "       (2,\"Ramarao Dandamudi\",1,\"2010\",\"20\",\"M\",4000),\n",
    "       (3,\"Mahender\",1,\"2010\",\"10\",\"M\",1000),\n",
    "       (4,\"Snigdha Kantamaneni\",3,\"2005\",\"10\",\"F\",2000),\n",
    "       (5,\"Divyasree Gothipati\",3,\"2010\",\"40\",\"F\",1500),\n",
    "       (6,\"Ramu Nagisetty\",1,\"2010\",\"50\",\"M\",2800),\n",
    "       (7,\"Dhawan Rachakonda\",2,\"2010\",\"50\",\"M\",3600)\n",
    "       ]\n",
    "empColumns = [\"emp_id\",\"name\",\"manager_id\",\"year_joined\",\n",
    "              \"dept_id\",\"gender\",\"salary\"]\n",
    "\n",
    "empDF = spark.createDataFrame(data=emp, schema = empColumns)\n",
    "empDF.printSchema()\n",
    "empDF.show(truncate=False)\n",
    "\n",
    "dept = [(\"Finance\",10),\n",
    "        (\"Marketing\",20),\n",
    "        (\"Sales\",30),\n",
    "        (\"IT\",40)\n",
    "        ]\n",
    "deptColumns = [\"dept_name\",\"dept_id\"]\n",
    "deptDF = spark.createDataFrame(data=dept, schema = deptColumns)\n",
    "deptDF.printSchema()\n",
    "deptDF.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+----------+-----------+-------+------+------+---------+-------+\n",
      "|emp_id|               name|manager_id|year_joined|dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+-------------------+----------+-----------+-------+------+------+---------+-------+\n",
      "|     1|       Pavan Mantha|        -1|       2018|     10|     M|  3000|  Finance|     10|\n",
      "|     3|           Mahender|         1|       2010|     10|     M|  1000|  Finance|     10|\n",
      "|     4|Snigdha Kantamaneni|         3|       2005|     10|     F|  2000|  Finance|     10|\n",
      "|     2|  Ramarao Dandamudi|         1|       2010|     20|     M|  4000|Marketing|     20|\n",
      "|     5|Divyasree Gothipati|         3|       2010|     40|     F|  1500|       IT|     40|\n",
      "+------+-------------------+----------+-----------+-------+------+------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDF.join(deptDF, empDF.dept_id == deptDF.dept_id, \"inner\").show(truncate=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+----------+-----------+-------+------+------+---------+-------+\n",
      "|emp_id|name               |manager_id|year_joined|dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+-------------------+----------+-----------+-------+------+------+---------+-------+\n",
      "|1     |Pavan Mantha       |-1        |2018       |10     |M     |3000  |Finance  |10     |\n",
      "|3     |Mahender           |1         |2010       |10     |M     |1000  |Finance  |10     |\n",
      "|4     |Snigdha Kantamaneni|3         |2005       |10     |F     |2000  |Finance  |10     |\n",
      "|2     |Ramarao Dandamudi  |1         |2010       |20     |M     |4000  |Marketing|20     |\n",
      "|null  |null               |null      |null       |null   |null  |null  |Sales    |30     |\n",
      "|5     |Divyasree Gothipati|3         |2010       |40     |F     |1500  |IT       |40     |\n",
      "|6     |Ramu Nagisetty     |1         |2010       |50     |M     |2800  |null     |null   |\n",
      "|7     |Dhawan Rachakonda  |2         |2010       |50     |M     |3600  |null     |null   |\n",
      "+------+-------------------+----------+-----------+-------+------+------+---------+-------+\n",
      "\n",
      "+------+-------------------+----------+-----------+-------+------+------+---------+-------+\n",
      "|emp_id|name               |manager_id|year_joined|dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+-------------------+----------+-----------+-------+------+------+---------+-------+\n",
      "|1     |Pavan Mantha       |-1        |2018       |10     |M     |3000  |Finance  |10     |\n",
      "|3     |Mahender           |1         |2010       |10     |M     |1000  |Finance  |10     |\n",
      "|4     |Snigdha Kantamaneni|3         |2005       |10     |F     |2000  |Finance  |10     |\n",
      "|2     |Ramarao Dandamudi  |1         |2010       |20     |M     |4000  |Marketing|20     |\n",
      "|null  |null               |null      |null       |null   |null  |null  |Sales    |30     |\n",
      "|5     |Divyasree Gothipati|3         |2010       |40     |F     |1500  |IT       |40     |\n",
      "|6     |Ramu Nagisetty     |1         |2010       |50     |M     |2800  |null     |null   |\n",
      "|7     |Dhawan Rachakonda  |2         |2010       |50     |M     |3600  |null     |null   |\n",
      "+------+-------------------+----------+-----------+-------+------+------+---------+-------+\n",
      "\n",
      "+------+-------------------+----------+-----------+-------+------+------+---------+-------+\n",
      "|emp_id|name               |manager_id|year_joined|dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+-------------------+----------+-----------+-------+------+------+---------+-------+\n",
      "|1     |Pavan Mantha       |-1        |2018       |10     |M     |3000  |Finance  |10     |\n",
      "|3     |Mahender           |1         |2010       |10     |M     |1000  |Finance  |10     |\n",
      "|4     |Snigdha Kantamaneni|3         |2005       |10     |F     |2000  |Finance  |10     |\n",
      "|2     |Ramarao Dandamudi  |1         |2010       |20     |M     |4000  |Marketing|20     |\n",
      "|null  |null               |null      |null       |null   |null  |null  |Sales    |30     |\n",
      "|5     |Divyasree Gothipati|3         |2010       |40     |F     |1500  |IT       |40     |\n",
      "|6     |Ramu Nagisetty     |1         |2010       |50     |M     |2800  |null     |null   |\n",
      "|7     |Dhawan Rachakonda  |2         |2010       |50     |M     |3600  |null     |null   |\n",
      "+------+-------------------+----------+-----------+-------+------+------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDF.join(deptDF,empDF.dept_id ==  deptDF.dept_id,\"outer\").show(truncate=False)\n",
    "empDF.join(deptDF,empDF.dept_id ==  deptDF.dept_id,\"full\").show(truncate=False)\n",
    "empDF.join(deptDF,empDF.dept_id ==  deptDF.dept_id,\"fullouter\").show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## union() functions in PySpark SQL"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- emp_id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- manager_id: long (nullable = true)\n",
      " |-- year_joined: string (nullable = true)\n",
      " |-- dept_id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n",
      "+------+---------------+----------+-----------+-------+------+------+\n",
      "|emp_id|name           |manager_id|year_joined|dept_id|gender|salary|\n",
      "+------+---------------+----------+-----------+-------+------+------+\n",
      "|8     |Ashwini Vangala|-1        |2018       |10     |M     |3000  |\n",
      "|9     |Akhil Debral   |8         |2010       |20     |M     |4000  |\n",
      "|10    |Nishant Sharma |8         |2010       |10     |M     |1000  |\n",
      "|11    |Ramai V        |10        |2005       |10     |F     |2000  |\n",
      "|12    |Ravi Teja      |10        |2010       |40     |M     |1500  |\n",
      "|13    |Rajib          |-1        |2010       |50     |M     |2800  |\n",
      "|14    |Utkarsh Upadyay|9         |2010       |50     |M     |3600  |\n",
      "+------+---------------+----------+-----------+-------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp = [(8,\"Ashwini Vangala\",-1,\"2018\",\"10\",\"M\",3000),\n",
    "       (9,\"Akhil Debral\",8,\"2010\",\"20\",\"M\",4000),\n",
    "       (10,\"Nishant Sharma\",8,\"2010\",\"10\",\"M\",1000),\n",
    "       (11,\"Ramai V\",10,\"2005\",\"10\",\"F\",2000),\n",
    "       (12,\"Ravi Teja\",10,\"2010\",\"40\",\"M\",1500),\n",
    "       (13,\"Rajib\",-1,\"2010\",\"50\",\"M\",2800),\n",
    "       (14,\"Utkarsh Upadyay\",9,\"2010\",\"50\",\"M\",3600)\n",
    "       ]\n",
    "empColumns = [\"emp_id\",\"name\",\"manager_id\",\"year_joined\",\n",
    "              \"dept_id\",\"gender\",\"salary\"]\n",
    "\n",
    "empDF2 = spark.createDataFrame(data=emp, schema = empColumns)\n",
    "empDF2.printSchema()\n",
    "empDF2.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+----------+-----------+-------+------+------+\n",
      "|emp_id|name               |manager_id|year_joined|dept_id|gender|salary|\n",
      "+------+-------------------+----------+-----------+-------+------+------+\n",
      "|1     |Pavan Mantha       |-1        |2018       |10     |M     |3000  |\n",
      "|2     |Ramarao Dandamudi  |1         |2010       |20     |M     |4000  |\n",
      "|3     |Mahender           |1         |2010       |10     |M     |1000  |\n",
      "|4     |Snigdha Kantamaneni|3         |2005       |10     |F     |2000  |\n",
      "|5     |Divyasree Gothipati|3         |2010       |40     |F     |1500  |\n",
      "|6     |Ramu Nagisetty     |1         |2010       |50     |M     |2800  |\n",
      "|7     |Dhawan Rachakonda  |2         |2010       |50     |M     |3600  |\n",
      "|8     |Ashwini Vangala    |-1        |2018       |10     |M     |3000  |\n",
      "|9     |Akhil Debral       |8         |2010       |20     |M     |4000  |\n",
      "|10    |Nishant Sharma     |8         |2010       |10     |M     |1000  |\n",
      "|11    |Ramai V            |10        |2005       |10     |F     |2000  |\n",
      "|12    |Ravi Teja          |10        |2010       |40     |M     |1500  |\n",
      "|13    |Rajib              |-1        |2010       |50     |M     |2800  |\n",
      "|14    |Utkarsh Upadyay    |9         |2010       |50     |M     |3600  |\n",
      "+------+-------------------+----------+-----------+-------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unionDF = empDF.union(empDF2)\n",
    "unionDF.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## usage of map() function in PySpark"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+----------+-----------+-------+------+------+\n",
      "|emp_id|               name|manager_id|year_joined|dept_id|gender|salary|\n",
      "+------+-------------------+----------+-----------+-------+------+------+\n",
      "|     1|       PAVAN MANTHA|        -1|       2018|     10|     M|  3000|\n",
      "|     2|  RAMARAO DANDAMUDI|         1|       2010|     20|     M|  4000|\n",
      "|     3|           MAHENDER|         1|       2010|     10|     M|  1000|\n",
      "|     4|SNIGDHA KANTAMANENI|         3|       2005|     10|     F|  2000|\n",
      "|     5|DIVYASREE GOTHIPATI|         3|       2010|     40|     F|  1500|\n",
      "|     6|     RAMU NAGISETTY|         1|       2010|     50|     M|  2800|\n",
      "|     7|  DHAWAN RACHAKONDA|         2|       2010|     50|     M|  3600|\n",
      "|     8|    ASHWINI VANGALA|        -1|       2018|     10|     M|  3000|\n",
      "|     9|       AKHIL DEBRAL|         8|       2010|     20|     M|  4000|\n",
      "|    10|     NISHANT SHARMA|         8|       2010|     10|     M|  1000|\n",
      "|    11|            RAMAI V|        10|       2005|     10|     F|  2000|\n",
      "|    12|          RAVI TEJA|        10|       2010|     40|     M|  1500|\n",
      "|    13|              RAJIB|        -1|       2010|     50|     M|  2800|\n",
      "|    14|    UTKARSH UPADYAY|         9|       2010|     50|     M|  3600|\n",
      "+------+-------------------+----------+-----------+-------+------+------+\n",
      "\n",
      "+------+-------------------+----------+-----------+-------+------+------+\n",
      "|emp_id|               name|manager_id|year_joined|dept_id|gender|salary|\n",
      "+------+-------------------+----------+-----------+-------+------+------+\n",
      "|     1|       Pavan Mantha|        -1|       2018|     10|     M|  6000|\n",
      "|     2|  Ramarao Dandamudi|         1|       2010|     20|     M|  8000|\n",
      "|     3|           Mahender|         1|       2010|     10|     M|  2000|\n",
      "|     4|Snigdha Kantamaneni|         3|       2005|     10|     F|  4000|\n",
      "|     5|Divyasree Gothipati|         3|       2010|     40|     F|  3000|\n",
      "|     6|     Ramu Nagisetty|         1|       2010|     50|     M|  5600|\n",
      "|     7|  Dhawan Rachakonda|         2|       2010|     50|     M|  7200|\n",
      "|     8|    Ashwini Vangala|        -1|       2018|     10|     M|  6000|\n",
      "|     9|       Akhil Debral|         8|       2010|     20|     M|  8000|\n",
      "|    10|     Nishant Sharma|         8|       2010|     10|     M|  2000|\n",
      "|    11|            Ramai V|        10|       2005|     10|     F|  4000|\n",
      "|    12|          Ravi Teja|        10|       2010|     40|     M|  3000|\n",
      "|    13|              Rajib|        -1|       2010|     50|     M|  5600|\n",
      "|    14|    Utkarsh Upadyay|         9|       2010|     50|     M|  7200|\n",
      "+------+-------------------+----------+-----------+-------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Refering columns by index.\n",
    "rdd2=unionDF.rdd.map(lambda x:(x[0],x[1].upper(),x[2],x[3],x[4],x[5],x[6]))\n",
    "df2=rdd2.toDF(schema=empColumns)\n",
    "df2.show()\n",
    "\n",
    "# Referring Column Names\n",
    "rdd2=unionDF.rdd.map(lambda x:(x[\"emp_id\"],x[\"name\"],x[\"manager_id\"],x[\"year_joined\"],x[\"dept_id\"],x[\"gender\"],x[\"salary\"]*2))\n",
    "df2=rdd2.toDF(schema=empColumns)\n",
    "df2.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MapType(), map_keys(), map_values(), explode() functions in pyspark"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField('name', StringType(), True),\n",
    "    StructField('properties', MapType(StringType(),BooleanType()),True)\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- properties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: boolean (valueContainsNull = true)\n",
      "\n",
      "+-----------------+---------------------------------------+\n",
      "|name             |properties                             |\n",
      "+-----------------+---------------------------------------+\n",
      "|Pavan Mantha     |{SparkSQL -> true, Snowflake -> false} |\n",
      "|Arun Boppudi     |{SparkSQL -> true, Snowflake -> true}  |\n",
      "|Ravi Vadlamani   |{SparkSQL -> false, Snowflake -> false}|\n",
      "|Ramu Nagisetty   |{SparkSQL -> true, Snowflake -> false} |\n",
      "|Ramarao Dandamudi|{SparkSQL -> false, Snowflake -> false}|\n",
      "+-----------------+---------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('sparkdev').getOrCreate()\n",
    "dataDictionary = [\n",
    "    ('Pavan Mantha',{'SparkSQL':True,'Snowflake':False}),\n",
    "    ('Arun Boppudi',{'SparkSQL':True,'Snowflake':True}),\n",
    "    ('Ravi Vadlamani',{'SparkSQL':False,'Snowflake':False}),\n",
    "    ('Ramu Nagisetty',{'SparkSQL':True,'Snowflake':False}),\n",
    "    ('Ramarao Dandamudi',{'SparkSQL':False,'Snowflake':False})\n",
    "]\n",
    "df = spark.createDataFrame(data=dataDictionary, schema = schema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- SparkSQL: boolean (nullable = true)\n",
      " |-- SnowFlake: boolean (nullable = true)\n",
      "\n",
      "+-----------------+--------+---------+\n",
      "|name             |SparkSQL|SnowFlake|\n",
      "+-----------------+--------+---------+\n",
      "|Pavan Mantha     |true    |false    |\n",
      "|Arun Boppudi     |true    |true     |\n",
      "|Ravi Vadlamani   |false   |false    |\n",
      "|Ramu Nagisetty   |true    |false    |\n",
      "|Ramarao Dandamudi|false   |false    |\n",
      "+-----------------+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = df.rdd.map(lambda x: (x[\"name\"], x.properties[\"SparkSQL\"], x.properties[\"Snowflake\"])).toDF([\"name\",\"SparkSQL\",\"SnowFlake\"])\n",
    "df2.printSchema()\n",
    "df2.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+---------+\n",
      "|name          |SparkSQL|SnowFlake|\n",
      "+--------------+--------+---------+\n",
      "|Pavan Mantha  |true    |false    |\n",
      "|Ramu Nagisetty|true    |false    |\n",
      "+--------------+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.select(\"*\").where(df2[\"SparkSQL\"] == True).where(df2[\"Snowflake\"] == False).show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------+-----+\n",
      "|             name|      key|value|\n",
      "+-----------------+---------+-----+\n",
      "|     Pavan Mantha| SparkSQL| true|\n",
      "|     Pavan Mantha|Snowflake|false|\n",
      "|     Arun Boppudi| SparkSQL| true|\n",
      "|     Arun Boppudi|Snowflake| true|\n",
      "|   Ravi Vadlamani| SparkSQL|false|\n",
      "|   Ravi Vadlamani|Snowflake|false|\n",
      "|   Ramu Nagisetty| SparkSQL| true|\n",
      "|   Ramu Nagisetty|Snowflake|false|\n",
      "|Ramarao Dandamudi| SparkSQL|false|\n",
      "|Ramarao Dandamudi|Snowflake|false|\n",
      "+-----------------+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.name, explode(df.properties)).show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------------------+\n",
      "|name             |map_keys(properties) |\n",
      "+-----------------+---------------------+\n",
      "|Pavan Mantha     |[SparkSQL, Snowflake]|\n",
      "|Arun Boppudi     |[SparkSQL, Snowflake]|\n",
      "|Ravi Vadlamani   |[SparkSQL, Snowflake]|\n",
      "|Ramu Nagisetty   |[SparkSQL, Snowflake]|\n",
      "|Ramarao Dandamudi|[SparkSQL, Snowflake]|\n",
      "+-----------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.name, map_keys(df.properties)).show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------------+\n",
      "|name             |map_values(properties)|\n",
      "+-----------------+----------------------+\n",
      "|Pavan Mantha     |[true, false]         |\n",
      "|Arun Boppudi     |[true, true]          |\n",
      "|Ravi Vadlamani   |[false, false]        |\n",
      "|Ramu Nagisetty   |[true, false]         |\n",
      "|Ramarao Dandamudi|[false, false]        |\n",
      "+-----------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.name, map_values(df.properties)).show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## use of date functions in pyspark"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=spark.createDataFrame(\n",
    "    data = [ (\"1\",\"2023-03-19 08:57:00.000\")],\n",
    "    schema=[\"id\",\"timestamp\"])\n",
    "df.printSchema()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------------+-------------------+\n",
      "|id |timestamp              |timestamp_datetime |\n",
      "+---+-----------------------+-------------------+\n",
      "|1  |2023-03-19 08:57:00.000|2023-03-19 08:57:00|\n",
      "+---+-----------------------+-------------------+\n",
      "\n",
      "+---+-----------------------+-------------------+\n",
      "|id |timestamp              |timestamp_string   |\n",
      "+---+-----------------------+-------------------+\n",
      "|1  |2023-03-19 08:57:00.000|2023-03-19 08:57:00|\n",
      "+---+-----------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Timestamp String to DateType\n",
    "df.withColumn(\"timestamp_datetime\",to_timestamp(\"timestamp\")) \\\n",
    "    .show(truncate=False)\n",
    "\n",
    "# Using Cast to convert TimestampType to DateType\n",
    "df.withColumn('timestamp_string', \\\n",
    "              to_timestamp('timestamp').cast('string')) \\\n",
    "    .show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|          timestamp|\n",
      "+-------------------+\n",
      "|2023-03-19 08:57:00|\n",
      "+-------------------+\n",
      "\n",
      "+-------------------+\n",
      "|          timestamp|\n",
      "+-------------------+\n",
      "|2023-03-19 08:57:00|\n",
      "+-------------------+\n",
      "\n",
      "+-------------------+\n",
      "|          timestamp|\n",
      "+-------------------+\n",
      "|2023-03-19 08:57:00|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SQL string to TimestampType\n",
    "spark.sql(\"select to_timestamp('2023-03-19 08:57:00.000') as timestamp\").show()\n",
    "#SQL CAST timestamp string to TimestampType\n",
    "spark.sql(\"select timestamp('2023-03-19 08:57:00.000') as timestamp\").show()\n",
    "#SQL Custom string to TimestampType\n",
    "spark.sql(\"select to_timestamp('03-19-2023 08:57:00.000','MM-dd-yyyy HH:mm:ss.SSSS') as timestamp\").show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
