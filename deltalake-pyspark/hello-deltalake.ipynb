{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from delta.pip_utils import configure_spark_with_delta_pip\n",
    "from delta.tables import DeltaTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "SparkDeltalakeConfig = SparkSession.builder\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .appName(\"sparkdev-deltalake\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Users/pavanmantha/venv-metal/lib/python3.11/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/pavanmantha/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/pavanmantha/.ivy2/jars\n",
      "io.delta#delta-spark_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-d0237427-3663-466e-a240-dc7588833b23;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-spark_2.12;3.0.0 in central\n",
      "\tfound io.delta#delta-storage;3.0.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
      "downloading https://repo1.maven.org/maven2/io/delta/delta-spark_2.12/3.0.0/delta-spark_2.12-3.0.0.jar ...\n",
      "\t[SUCCESSFUL ] io.delta#delta-spark_2.12;3.0.0!delta-spark_2.12.jar (1293ms)\n",
      "downloading https://repo1.maven.org/maven2/io/delta/delta-storage/3.0.0/delta-storage-3.0.0.jar ...\n",
      "\t[SUCCESSFUL ] io.delta#delta-storage;3.0.0!delta-storage.jar (307ms)\n",
      "downloading https://repo1.maven.org/maven2/org/antlr/antlr4-runtime/4.9.3/antlr4-runtime-4.9.3.jar ...\n",
      "\t[SUCCESSFUL ] org.antlr#antlr4-runtime;4.9.3!antlr4-runtime.jar (312ms)\n",
      ":: resolution report :: resolve 4739ms :: artifacts dl 1914ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-spark_2.12;3.0.0 from central in [default]\n",
      "\tio.delta#delta-storage;3.0.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   3   |   3   |   0   ||   3   |   3   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-d0237427-3663-466e-a240-dc7588833b23\n",
      "\tconfs: [default]\n",
      "\t3 artifacts copied, 0 already retrieved (5230kB/9ms)\n",
      "23/10/19 15:48:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = configure_spark_with_delta_pip(SparkDeltalakeConfig).getOrCreate()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField('Id', IntegerType(), True), # ID\n",
    "    StructField('Date', StringType(), True), #date\n",
    "    StructField('Location', StringType(), True),\n",
    "    StructField('MinTemp', StringType(), True),\n",
    "    StructField('MaxTemp', StringType(), True),\n",
    "    StructField('Rainfall', StringType(), True)\n",
    "    # AND OTHER FIELDS OMITTED TO MAKE THIS CODE BLOCK SMALL\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/19 15:48:41 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 25, schema size: 6\n",
      "CSV file: file:///Users/pavanmantha/Pavans/PracticeExamples/DataScience_Practice/spark-handson/deltalake-pyspark/data/weather.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------+-------+-------+--------+\n",
      "| Id|      Date|Location|MinTemp|MaxTemp|Rainfall|\n",
      "+---+----------+--------+-------+-------+--------+\n",
      "|  0|2008-12-01|  Albury|   13.4|   22.9|     0.6|\n",
      "|  1|2008-12-02|  Albury|    7.4|   25.1|     0.0|\n",
      "|  2|2008-12-03|  Albury|   12.9|   25.7|     0.0|\n",
      "|  3|2008-12-04|  Albury|    9.2|   28.0|     0.0|\n",
      "|  4|2008-12-05|  Albury|   17.5|   32.3|     1.0|\n",
      "+---+----------+--------+-------+-------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_weather = (\n",
    "    spark\n",
    "    .read.format(\"csv\")\n",
    "    .option(\"delimiter\", \",\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"encoding\", \"ISO-8859-1\")\n",
    "    .option('overwriteSchema', True)\n",
    "    .schema(schema=schema)\n",
    "    .load(\"./data/weather.csv\")\n",
    ")\n",
    "\n",
    "df_weather.show(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/19 15:48:44 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 25, schema size: 6\n",
      "CSV file: file:///Users/pavanmantha/Pavans/PracticeExamples/DataScience_Practice/spark-handson/deltalake-pyspark/data/weather.csv\n",
      "23/10/19 15:48:46 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "23/10/19 15:48:46 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_weather.write.format(\"delta\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .option('mergeSchema', True)\\\n",
    "    .saveAsTable(\"weather_delta_master\")\n",
    "    #.save(\"./delta\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#df_weather_delta = spark.read.format(\"delta\").load(\"./delta\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "#df_weather_delta.select([\"Date\",\"MaxTemp\"]).show(5, truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "#df_weather_delta.count()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Read data from the delta lake using SQL"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------+-------+-------+--------+\n",
      "|Id |Date      |Location|MinTemp|MaxTemp|Rainfall|\n",
      "+---+----------+--------+-------+-------+--------+\n",
      "|0  |2008-12-01|Albury  |13.4   |22.9   |0.6     |\n",
      "|1  |2008-12-02|Albury  |7.4    |25.1   |0.0     |\n",
      "|2  |2008-12-03|Albury  |12.9   |25.7   |0.0     |\n",
      "|3  |2008-12-04|Albury  |9.2    |28.0   |0.0     |\n",
      "|4  |2008-12-05|Albury  |17.5   |32.3   |1.0     |\n",
      "|5  |2008-12-06|Albury  |14.6   |29.7   |0.2     |\n",
      "|6  |2008-12-07|Albury  |14.3   |25.0   |0.0     |\n",
      "|7  |2008-12-08|Albury  |7.7    |26.7   |0.0     |\n",
      "|8  |2008-12-09|Albury  |9.7    |31.9   |0.0     |\n",
      "|9  |2008-12-10|Albury  |13.1   |30.1   |1.4     |\n",
      "+---+----------+--------+-------+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from weather_delta_master\").limit(10).show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+\n",
      "|location     |_count|\n",
      "+-------------+------+\n",
      "|Albury       |3011  |\n",
      "|Cobar        |2988  |\n",
      "|NorfolkIsland|2964  |\n",
      "|Newcastle    |2955  |\n",
      "|CoffsHarbour |2953  |\n",
      "|NorahHead    |2929  |\n",
      "|BadgerysCreek|2928  |\n",
      "|Moree        |2854  |\n",
      "|Penrith      |1418  |\n",
      "+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select location, count(*) as _count from weather_delta_master '\n",
    "          'group by location order by _count desc').show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+\n",
      "|location     |MAX_TEMP|\n",
      "+-------------+--------+\n",
      "|Penrith      |46.5    |\n",
      "|BadgerysCreek|46.4    |\n",
      "|Newcastle    |44.1    |\n",
      "|NorahHead    |44.0    |\n",
      "|CoffsHarbour |39.2    |\n",
      "|NorfolkIsland|28.4    |\n",
      "|Albury       |9.9     |\n",
      "|Cobar        |9.7     |\n",
      "|Moree        |9.6     |\n",
      "+-------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    'SELECT location, max(MaxTemp) AS MAX_TEMP FROM weather_delta_master GROUP BY location ORDER BY CAST(MAX_TEMP AS FLOAT) DESC'\n",
    ").show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------+-------+\n",
      "|col_name       |data_type|comment|\n",
      "+---------------+---------+-------+\n",
      "|Id             |int      |       |\n",
      "|Date           |string   |       |\n",
      "|Location       |string   |       |\n",
      "|MinTemp        |string   |       |\n",
      "|MaxTemp        |string   |       |\n",
      "|Rainfall       |string   |       |\n",
      "|               |         |       |\n",
      "|# Partitioning |         |       |\n",
      "|Not partitioned|         |       |\n",
      "+---------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DESCRIBE TABLE weather_delta_master\").limit(10).show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Check delta table versions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "dt = DeltaTable.forName(spark, \"weather_delta_master\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------------+\n",
      "|version|timestamp              |\n",
      "+-------+-----------------------+\n",
      "|2      |2023-05-26 07:19:01.864|\n",
      "|1      |2023-05-25 20:43:06.7  |\n",
      "|0      |2023-05-25 20:41:50.456|\n",
      "+-------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt.history().select(\"version\",\"timestamp\").show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------+-------+-------+--------+\n",
      "|Id |Date      |Location|MinTemp|MaxTemp|Rainfall|\n",
      "+---+----------+--------+-------+-------+--------+\n",
      "|0  |2008-12-01|Albury  |13.4   |22.9   |0.6     |\n",
      "|1  |2008-12-02|Albury  |7.4    |25.1   |0.0     |\n",
      "|2  |2008-12-03|Albury  |12.9   |25.7   |0.0     |\n",
      "|3  |2008-12-04|Albury  |9.2    |28.0   |0.0     |\n",
      "|4  |2008-12-05|Albury  |17.5   |32.3   |1.0     |\n",
      "|5  |2008-12-06|Albury  |14.6   |29.7   |0.2     |\n",
      "|6  |2008-12-07|Albury  |14.3   |25.0   |0.0     |\n",
      "|7  |2008-12-08|Albury  |7.7    |26.7   |0.0     |\n",
      "|8  |2008-12-09|Albury  |9.7    |31.9   |0.0     |\n",
      "|9  |2008-12-10|Albury  |13.1   |30.1   |1.4     |\n",
      "|10 |2008-12-11|Albury  |13.4   |30.4   |0.0     |\n",
      "|11 |2008-12-12|Albury  |15.9   |21.7   |2.2     |\n",
      "|12 |2008-12-13|Albury  |15.9   |18.6   |15.6    |\n",
      "|13 |2008-12-14|Albury  |12.6   |21.0   |3.6     |\n",
      "|14 |2008-12-16|Albury  |9.8    |27.7   |null    |\n",
      "|15 |2008-12-17|Albury  |14.1   |20.9   |0.0     |\n",
      "|16 |2008-12-18|Albury  |13.5   |22.9   |16.8    |\n",
      "|17 |2008-12-19|Albury  |11.2   |22.5   |10.6    |\n",
      "|18 |2008-12-20|Albury  |9.8    |25.6   |0.0     |\n",
      "|19 |2008-12-21|Albury  |11.5   |29.3   |0.0     |\n",
      "+---+----------+--------+-------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT * FROM weather_delta_master VERSION as of 1').show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
