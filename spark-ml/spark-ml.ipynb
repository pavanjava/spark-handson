{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"sparkdev-ML-tutorial\").master(\"local[*]\").getOrCreate()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sepal_length(cm): string (nullable = true)\n",
      " |-- sepal_width(cm): string (nullable = true)\n",
      " |-- petal_length(cm): string (nullable = true)\n",
      " |-- petal_width(cm): string (nullable = true)\n",
      " |-- target: string (nullable = true)\n",
      "\n",
      "+----------------+---------------+----------------+---------------+-----------+\n",
      "|sepal_length(cm)|sepal_width(cm)|petal_length(cm)|petal_width(cm)|target     |\n",
      "+----------------+---------------+----------------+---------------+-----------+\n",
      "|5.1             |3.5            |1.4             |0.2            |Iris-setosa|\n",
      "|4.9             |3.0            |1.4             |0.2            |Iris-setosa|\n",
      "|4.7             |3.2            |1.3             |0.2            |Iris-setosa|\n",
      "|4.6             |3.1            |1.5             |0.2            |Iris-setosa|\n",
      "|5.0             |3.6            |1.4             |0.2            |Iris-setosa|\n",
      "|5.4             |3.9            |1.7             |0.4            |Iris-setosa|\n",
      "|4.6             |3.4            |1.4             |0.3            |Iris-setosa|\n",
      "|5.0             |3.4            |1.5             |0.2            |Iris-setosa|\n",
      "|4.4             |2.9            |1.4             |0.2            |Iris-setosa|\n",
      "|4.9             |3.1            |1.5             |0.1            |Iris-setosa|\n",
      "+----------------+---------------+----------------+---------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(path='iris_dataset.csv',header=True)\n",
    "df.printSchema()\n",
    "df.show(10, truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sepal_length(cm): double (nullable = true)\n",
      " |-- sepal_width(cm): double (nullable = true)\n",
      " |-- petal_length(cm): double (nullable = true)\n",
      " |-- petal_width(cm): double (nullable = true)\n",
      " |-- target: string (nullable = true)\n",
      "\n",
      "+----------------+---------------+----------------+---------------+-----------+\n",
      "|sepal_length(cm)|sepal_width(cm)|petal_length(cm)|petal_width(cm)|     target|\n",
      "+----------------+---------------+----------------+---------------+-----------+\n",
      "|             5.1|            3.5|             1.4|            0.2|Iris-setosa|\n",
      "|             4.9|            3.0|             1.4|            0.2|Iris-setosa|\n",
      "|             4.7|            3.2|             1.3|            0.2|Iris-setosa|\n",
      "|             4.6|            3.1|             1.5|            0.2|Iris-setosa|\n",
      "|             5.0|            3.6|             1.4|            0.2|Iris-setosa|\n",
      "+----------------+---------------+----------------+---------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_columns = ['sepal_length(cm)','sepal_width(cm)','petal_length(cm)','petal_width(cm)']\n",
    "\n",
    "# Assuming your dataframe is named \"df\" and the columns you want to convert are \"col1\", \"col2\", \"col3\"\n",
    "df = df.select([col(c).cast(\"double\").alias(c) if c in input_columns else col(c) for c in df.columns])\n",
    "df.printSchema()\n",
    "df.show(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------------+----------------+---------------+-----------+-----------------+\n",
      "|sepal_length(cm)|sepal_width(cm)|petal_length(cm)|petal_width(cm)|target     |features         |\n",
      "+----------------+---------------+----------------+---------------+-----------+-----------------+\n",
      "|5.1             |3.5            |1.4             |0.2            |Iris-setosa|[5.1,3.5,1.4,0.2]|\n",
      "|4.9             |3.0            |1.4             |0.2            |Iris-setosa|[4.9,3.0,1.4,0.2]|\n",
      "|4.7             |3.2            |1.3             |0.2            |Iris-setosa|[4.7,3.2,1.3,0.2]|\n",
      "|4.6             |3.1            |1.5             |0.2            |Iris-setosa|[4.6,3.1,1.5,0.2]|\n",
      "|5.0             |3.6            |1.4             |0.2            |Iris-setosa|[5.0,3.6,1.4,0.2]|\n",
      "+----------------+---------------+----------------+---------------+-----------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vector_assembler = VectorAssembler(inputCols=input_columns, outputCol=\"features\", handleInvalid=\"skip\")\n",
    "transformed_df = vector_assembler.transform(df)\n",
    "transformed_df.show(5, truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+\n",
      "|target     |features         |\n",
      "+-----------+-----------------+\n",
      "|Iris-setosa|[5.1,3.5,1.4,0.2]|\n",
      "|Iris-setosa|[4.9,3.0,1.4,0.2]|\n",
      "|Iris-setosa|[4.7,3.2,1.3,0.2]|\n",
      "|Iris-setosa|[4.6,3.1,1.5,0.2]|\n",
      "|Iris-setosa|[5.0,3.6,1.4,0.2]|\n",
      "+-----------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "required_df = transformed_df.drop('sepal_length(cm)','sepal_width(cm)','petal_length(cm)','petal_width(cm)')\n",
    "required_df.show(5, truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|target         |\n",
      "+---------------+\n",
      "|Iris-virginica |\n",
      "|Iris-setosa    |\n",
      "|Iris-versicolor|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "required_df.select(col(\"target\")).distinct().show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+-------------+\n",
      "|target     |features         |targetIndexed|\n",
      "+-----------+-----------------+-------------+\n",
      "|Iris-setosa|[5.1,3.5,1.4,0.2]|0.0          |\n",
      "|Iris-setosa|[4.9,3.0,1.4,0.2]|0.0          |\n",
      "|Iris-setosa|[4.7,3.2,1.3,0.2]|0.0          |\n",
      "|Iris-setosa|[4.6,3.1,1.5,0.2]|0.0          |\n",
      "|Iris-setosa|[5.0,3.6,1.4,0.2]|0.0          |\n",
      "+-----------+-----------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "string_indexer = StringIndexer(inputCol='target', outputCol='targetIndexed')\n",
    "project_df = string_indexer.fit(required_df).transform(required_df)\n",
    "project_df.show(5, truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "(train_set, test_set) = project_df.randomSplit([0.8,0.2])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(featuresCol='features', labelCol='targetIndexed')\n",
    "model = dt.fit(train_set)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+-------------+--------------+-------------+----------+\n",
      "|target     |features         |targetIndexed|rawPrediction |probability  |prediction|\n",
      "+-----------+-----------------+-------------+--------------+-------------+----------+\n",
      "|Iris-setosa|[4.6,3.6,1.0,0.2]|0.0          |[37.0,0.0,0.0]|[1.0,0.0,0.0]|0.0       |\n",
      "|Iris-setosa|[4.9,3.0,1.4,0.2]|0.0          |[37.0,0.0,0.0]|[1.0,0.0,0.0]|0.0       |\n",
      "|Iris-setosa|[4.9,3.1,1.5,0.1]|0.0          |[37.0,0.0,0.0]|[1.0,0.0,0.0]|0.0       |\n",
      "|Iris-setosa|[5.0,3.0,1.6,0.2]|0.0          |[37.0,0.0,0.0]|[1.0,0.0,0.0]|0.0       |\n",
      "|Iris-setosa|[5.0,3.3,1.4,0.2]|0.0          |[37.0,0.0,0.0]|[1.0,0.0,0.0]|0.0       |\n",
      "|Iris-setosa|[5.0,3.5,1.3,0.3]|0.0          |[37.0,0.0,0.0]|[1.0,0.0,0.0]|0.0       |\n",
      "|Iris-setosa|[5.0,3.5,1.6,0.6]|0.0          |[37.0,0.0,0.0]|[1.0,0.0,0.0]|0.0       |\n",
      "|Iris-setosa|[5.1,3.4,1.5,0.2]|0.0          |[37.0,0.0,0.0]|[1.0,0.0,0.0]|0.0       |\n",
      "|Iris-setosa|[5.1,3.5,1.4,0.3]|0.0          |[37.0,0.0,0.0]|[1.0,0.0,0.0]|0.0       |\n",
      "|Iris-setosa|[5.4,3.7,1.5,0.2]|0.0          |[37.0,0.0,0.0]|[1.0,0.0,0.0]|0.0       |\n",
      "+-----------+-----------------+-------------+--------------+-------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(test_set)\n",
    "predictions.show(10, truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy= 0.821078431372549\n",
      "Test Error= 0.178921568627451\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol='targetIndexed', predictionCol='prediction')\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print('Accuracy=', accuracy)\n",
    "print('Test Error=', 1.0-accuracy)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(featuresCol='features',labelCol='targetIndexed', numTrees=10)\n",
    "model_rfc = rfc.fit(train_set)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+-------------+--------------+-------------+----------+\n",
      "|target     |features         |targetIndexed|rawPrediction |probability  |prediction|\n",
      "+-----------+-----------------+-------------+--------------+-------------+----------+\n",
      "|Iris-setosa|[4.6,3.6,1.0,0.2]|0.0          |[10.0,0.0,0.0]|[1.0,0.0,0.0]|0.0       |\n",
      "|Iris-setosa|[4.9,3.0,1.4,0.2]|0.0          |[10.0,0.0,0.0]|[1.0,0.0,0.0]|0.0       |\n",
      "|Iris-setosa|[4.9,3.1,1.5,0.1]|0.0          |[10.0,0.0,0.0]|[1.0,0.0,0.0]|0.0       |\n",
      "|Iris-setosa|[5.0,3.0,1.6,0.2]|0.0          |[10.0,0.0,0.0]|[1.0,0.0,0.0]|0.0       |\n",
      "|Iris-setosa|[5.0,3.3,1.4,0.2]|0.0          |[10.0,0.0,0.0]|[1.0,0.0,0.0]|0.0       |\n",
      "+-----------+-----------------+-------------+--------------+-------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_rfc = model_rfc.transform(test_set)\n",
    "predictions_rfc.show(5, truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy= 0.8487889273356402\n",
      "Test Error= 0.15121107266435985\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol='targetIndexed', predictionCol='prediction')\n",
    "accuracy = evaluator.evaluate(predictions_rfc)\n",
    "print('Accuracy=', accuracy)\n",
    "print('Test Error=', 1.0-accuracy)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
